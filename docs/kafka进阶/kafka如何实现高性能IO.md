## Kafka 是如何做到高性能的?
## 使用批处理提升服务端处理能力
我们知道,批处理是一种非常有效的提升系统吞吐量的方法.在kafka 内部,消息都是以批进行处理的.

在producer 端,当调用send()方法发送消息时,不论时同步发送还是异步发送,kafka 都不会立即将消息发送出去.它会先把消息
缓存在内存中,然后选择一个合适的时机将缓存的消息组成一批,一次性发给broker,如果在给定的时间内,缓存的消息仍然不能
组成一批,kafka 仍然会发送消息.简单来说,就是攒一波发一波.

在broker 端,kafka不会把一批消息还原成多条消息,在逐条处理.kafka 会吧没批消息都当作一个"批消息"处理.就是说,
在broker 端的处理流程中,无论是写磁盘 读磁盘 或者是将磁盘中的数据复制到其他的副本,批消息都不会解开.

在consumer 端,同样是以批为单位进行传递的,consumer 从broker 拉到一批消息后,在客户端把批消息进行还原,在逐条处理.

构建批消息和解开批消息分别在producer和consumer 进行,不仅减轻了broker 的压力,更重要的是减少了broker 处理请求的次数
,提升了系统的整体处理能力.
## 使用顺序读写提升磁盘IO 性能
对于磁盘来说,顺序读写的性能要远优于随机读写,在SSD 上,顺序读写的性能要比随机读写快好几倍,如果是机械硬盘,这个差距会
达到几十倍.为什么呢?

操作系统每次从磁盘读写数据的时候,需要先寻址,就是要先找到数据在磁盘上的物理位置,然后在进行数据读写.如果是机械硬盘
,这个寻址需要很长时间,应为它要移动磁头,这个是机械运动,机械硬盘工作的时候会发出咔咔的声音,就是磁头移动的声音.

顺序读写相比随机读写省去了大部分寻址时间,它只要寻址一次,就可以连续的读写下去.所以 性能要优于随机读写.

kafka 就是充分利用的磁盘的顺序读写优于随机读写特性.它的存储设计非常简单,对于每个分区,它把从producer 收到的消息,
顺序的写入对应的log 文件中,一个文件写满了,就开启一个新的文件顺序写下去.消费的时候,也是从某个全局的位置开始,顺序的
把消息读出来.
## 利用PageCache 加速消息读写
在kafka 中,它会利用PageCache 加速消息读写.PageCache 是现代操作系统都具有的一项基本特性.我们在调用系统API 读写文件
的时候,并不会直接去读写磁盘上的文件,应用程序实际操作的都是PageCache,也就是文件在内存缓存中的副本.

应用程序在写入文件的时候,操作系统会先把数据写入到内存中的PageCache,然后成批的写入到磁盘中.读取文件的时候,也是从PageCache
中,这个时候可能会出现两种情况.

    一种是PageCache 中有数据,那就直接读取,这样就节省了从磁盘读取数据的时间; 另一种是PageCache 中没有数据,
    这时候操作系统会引发一个缺页中断,应用程序的读取线程会被阻塞,操作系统把数据从文件中复制到PageCache 中,然后
    应用程序在从PageCache 中继续读取数据.这时会真正读取一次磁盘上的文件,这个读的过程会比较慢.
    
应用程序在使用完某块PageCache 后,并不会立即被清除掉,而是尽可能地使用空闲的物理内存保存这些PageCache.除非系统内除不够,
系统才会清理掉一部分PageCache,清理的策略一般是LRU 或它的变种算法.

大部分情况下,消费者读消息都会命中PageCache,好处是读取性能非常快,另外可以给写入消息让出磁盘的IO 资源,间接提升了写入性能.

## ZeroCopy: 零拷贝技术
kafka的消费端在消费的过程中,还使用了一种零拷贝技术的操作系统特性来进一步提升消费性能. 在consumer 的处理逻辑是
    
    首先从文件中找到消息数据,读到内存中;
    然后把消息通过网络发往客户端.
这个过程,实际做了2此或者3此复制:
    
    1. 从文件复制数据到PageCache中,如果命中PageCache,这一步可以省掉;
    2. 从PageCache复制到应用程序的内存空间,就是操作的对象所在的内存;
    2. 从应用程序的内存空间复制到Socket缓冲区,这个过程就是我们调用网路应用框架的API 发送数据的过程.
kafka 使用ZeroCopy技术可以把这个复制次数减少到一次,上面的2,3两次复制会合并成一次复制.直接从PageCache中把数据复制到
Socket缓冲区,这样不仅减少一次数据复制,更重要的是由于不用吧数据复制到用户内存空间中,DMA 控制器可以直接完成数据复制,
不需要CPU 参与,速度更快.
   
  
